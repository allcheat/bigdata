
Program for WordCount.java
import java.io.IOException; 
import java.util.*; 
import org.apache.hadoop.fs.Path; 
import org.apache.hadoop.conf.*; 
import org.apache.hadoop.io.*; 
import org.apache.hadoop.mapred.*; 
import org.apache.hadoop.util.*; 

public class WordCount 
{    
public static class Map extends MapReduceBase implements Mapper<LongWritable, Text, Text, IntWritable> 
{     
private final static IntWritable one = new IntWritable(1);      
private Text word = new Text();      
public void map(LongWritable key, Text value, OutputCollector<Text, IntWritable> output, Reporter reporter) throws IOException 
{        	
String line = value.toString();        
StringTokenizer tokenizer = new StringTokenizer(line);        
while (tokenizer.hasMoreTokens()) {          
word.set(tokenizer.nextToken());          
output.collect(word, one);        
}      
}    
}    

public static class Reduce extends MapReduceBase implements Reducer<Text, IntWritable, Text, IntWritable> 

{      
public void reduce(Text key, Iterator<IntWritable> values, OutputCollector<Text, IntWritable> output, Reporter reporter) throws IOException 
{        
int sum = 0;        
while (values.hasNext()) 
{          
sum += values.next().get();        
}        
output.collect(key, new IntWritable(sum));      
}    
}    

public static void main(String[] args) throws Exception 
{      

JobConf conf = new JobConf(WordCount.class);      conf.setJobName("wordcount");      
conf.setOutputKeyClass(Text.class);      conf.setOutputValueClass(IntWritable.class);      conf.setMapperClass(Map.class);      
conf.setCombinerClass(Reduce.class);      
conf.setReducerClass(Reduce.class);      conf.setInputFormat(TextInputFormat.class);      conf.setOutputFormat(TextOutputFormat.class);      FileInputFormat.setInputPaths(conf, new Path(args[0]));      FileOutputFormat.setOutputPath(conf, new Path(args[1]));      JobClient.runJob(conf);    
} 
}


Compile the WordCount.java program using the command as follows “javac -Xlint -classpath hadoop-0.20.1-core.jar -d WordCount/ /home/hduser/WordCount/WordCount.java”

Create the jar file using the command as follows “jar -cvf WordCount.jar -C WordCount/ .”


Create the input file file1.txt and file2.txt in the local area /home/hduser/WordCount/input 
To see the content present in the files use the “cat” command as follows

Before you run the wordcount program, create the directory /user/input in the dfs 
Then move the files present in the local input directory path to /user/input directory.

Running the WordCount using following command as “hadoop jar WordCount.jar WordCount /user/input /user/output”

After getting the output, it will stored in the dfs location “/user/output”
Then copy the output from the dfs location “/user/output” to local area using the command as “hadoop dfs –get /user/output /home/hduser/Desktop/output”
To see the output, go to concern location and use “cat” command to display the information 
